"""
ë‹¨ì¼ í™”ë©´ ì½”ë”© íŒíŠ¸ í‰ê°€ ì‹œìŠ¤í…œ
"""
import gradio as gr
import json
import os
import sys
from datetime import datetime
from typing import List, Dict, Optional
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€ (config.py importë¥¼ ìœ„í•´)
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from config import Config
from models.model_inference import ModelManager


class HintEvaluationApp:
    """íŒíŠ¸ í‰ê°€ ì• í”Œë¦¬ì¼€ì´ì…˜"""

    def __init__(self, data_path: str, auto_setup_models: bool = True):
        self.data_path = data_path
        self.problems = self.load_problems()
        self.model_manager = ModelManager(sequential_load=True)  # ìˆœì°¨ ë¡œë“œ í™œì„±í™”
        self.current_problem = None
        self.current_hints = {}  # ëª¨ë¸ë³„ íŒíŠ¸ ì €ì¥
        self.evaluation_results = []

        # í‰ê°€ ê²°ê³¼ ì €ì¥ ê²½ë¡œ (configì—ì„œ ìë™ ì„¤ì •)
        self.results_dir = Config.EVALUATION_RESULTS_DIR
        os.makedirs(self.results_dir, exist_ok=True)

        # ìë™ìœ¼ë¡œ ê¸°ë³¸ ëª¨ë¸ ì„¤ì •
        if auto_setup_models:
            self.setup_default_models()

    def setup_default_models(self):
        """ê¸°ë³¸ ëª¨ë¸ ìë™ ì„¤ì • (vLLM ìš°ì„ , HuggingFace í´ë°±)"""
        print("=" * 60)
        print("ğŸš€ ëª¨ë¸ ìë™ ì„¤ì • ì¤‘...")
        print("=" * 60)

        # vLLM ì„œë²„ ì—°ê²° ì‹œë„ (ë¹ ë¥¸ ì¶”ë¡ ì„ ìœ„í•´ ìš°ì„  ì‹œë„)
        vllm_url = Config.VLLM_SERVER_URL
        vllm_connected = False

        if vllm_url:
            print(f"\nâš¡ vLLM ì„œë²„ ì—°ê²° ì‹œë„: {vllm_url}")
            try:
                # vLLM ì„œë²„ì— ì—°ê²°ëœ ëª¨ë¸ ìë™ ê°ì§€ ë° ì¶”ê°€
                self.model_manager.add_vllm_model(
                    model_name="vLLM-Server",
                    model_path="auto",  # ì„œë²„ì—ì„œ ìë™ìœ¼ë¡œ ê°ì§€
                    base_url=vllm_url
                )
                print(f"âœ… vLLM ì„œë²„ ì—°ê²° ì„±ê³µ! (15-24ë°° ë¹ ë¥¸ ì¶”ë¡  ì†ë„)")
                vllm_connected = True
            except Exception as e:
                print(f"âš ï¸  vLLM ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
                print(f"    HuggingFace ëª¨ë¸ë¡œ í´ë°±í•©ë‹ˆë‹¤...")

        # vLLM ì—°ê²° ì‹¤íŒ¨ ì‹œ ë˜ëŠ” ì¶”ê°€ ëª¨ë¸ì´ í•„ìš”í•œ ê²½ìš°
        if not vllm_connected:
            print(f"\nğŸ“¦ HuggingFace ëª¨ë¸ ë¡œë”© ì¤‘ (ëŠë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)...")
            print(f"    ğŸ’¡ Tip: vLLM ì„œë²„ë¥¼ ì‚¬ìš©í•˜ë©´ 15-24ë°° ë¹ ë¦…ë‹ˆë‹¤!")
            print(f"    ì‹¤í–‰: python vllm_server.py --model Qwen/Qwen2.5-Coder-7B-Instruct\n")

            # ê°€ë²¼ìš´ ëª¨ë¸ 5ê°œ (ë¡œì»¬ HuggingFace Transformers)
            default_models = [
                {
                    "name": "Qwen2.5-Coder-1.5B",
                    "path": "Qwen/Qwen2.5-Coder-1.5B-Instruct",
                    "quantize": False,
                    "size": "1.5B"
                },
                {
                    "name": "DeepSeek-Coder-1.3B",
                    "path": "deepseek-ai/deepseek-coder-1.3b-instruct",
                    "quantize": False,
                    "size": "1.3B"
                },
                {
                    "name": "TinyLlama-1.1B",
                    "path": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
                    "quantize": False,
                    "size": "1.1B"
                },
                {
                    "name": "Phi-2-2.7B (4-bit)",
                    "path": "microsoft/phi-2",
                    "quantize": True,
                    "size": "2.7B"
                },
                {
                    "name": "CodeLlama-7B (4-bit)",
                    "path": "codellama/CodeLlama-7b-Instruct-hf",
                    "quantize": True,
                    "size": "7B"
                }
            ]

            for model_info in default_models:
                try:
                    print(f"\nğŸ“¦ {model_info['name']} ì„¤ì • ì¤‘...")
                    if model_info.get('quantize'):
                        print(f"  â†’ 4-bit ì–‘ìí™” ì‚¬ìš© (ë©”ëª¨ë¦¬ 1/4 ì ˆì•½)")
                    self.model_manager.add_huggingface_model(
                        model_info['name'],
                        model_info['path'],
                        use_quantization=model_info.get('quantize', False)
                    )
                    print(f"âœ… {model_info['name']} ì¶”ê°€ ì™„ë£Œ!")
                except Exception as e:
                    print(f"âš ï¸  {model_info['name']} ì¶”ê°€ ì‹¤íŒ¨: {e}")

        print("\n" + "=" * 60)
        print(f"âœ… ì´ {len(self.model_manager.get_available_models())}ê°œ ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!")
        if vllm_connected:
            print(f"âš¡ vLLM ê³ ì† ì¶”ë¡  í™œì„±í™”ë¨!")
        print("=" * 60)

    def load_problems(self) -> List[Dict]:
        """ë¬¸ì œ ë°ì´í„° ë¡œë“œ (multi-solution êµ¬ì¡°)"""
        with open(self.data_path, 'r', encoding='utf-8') as f:
            return json.load(f)

    def get_problem_list(self) -> List[str]:
        """ë¬¸ì œ ëª©ë¡ (ë“œë¡­ë‹¤ìš´ìš©)"""
        return [
            f"#{p['problem_id']} - {p['title']} (Level {p['level']})"
            for p in self.problems
        ]

    def load_problem(self, problem_selection: str):
        """ì„ íƒëœ ë¬¸ì œ ë¡œë“œ"""
        if not problem_selection:
            return self._empty_state()

        try:
            # ë¬¸ì œ ID ì¶”ì¶œ
            problem_id = problem_selection.split('#')[1].split(' -')[0].strip()

            # ë¬¸ì œ ì°¾ê¸°
            self.current_problem = None
            for p in self.problems:
                if str(p['problem_id']) == str(problem_id):
                    self.current_problem = p
                    break

            if not self.current_problem:
                return "âŒ ë¬¸ì œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", gr.update(value=""), *self._empty_hints()

            # ë¬¸ì œ ì •ë³´ í¬ë§·íŒ…
            problem_md = self._format_problem_display()

            # íŒíŠ¸ ì˜ì—­ ì´ˆê¸°í™”
            return problem_md, gr.update(value="# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"), *self._empty_hints()

        except Exception as e:
            print(f"[ERROR] ë¬¸ì œ ë¡œë“œ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return f"âŒ ì˜¤ë¥˜: {str(e)}", gr.update(value=""), *self._empty_hints()

    def _format_problem_display(self) -> str:
        """ë¬¸ì œ í‘œì‹œ í¬ë§·"""
        p = self.current_problem
        md = f"""# {p['title']}

**ë‚œì´ë„:** Level {p['level']} | **íƒœê·¸:** {', '.join(p['tags'])} | **ë¬¸ì œ ë§í¬:** [{p['problem_id']}]({p['url']})

---

## ğŸ“‹ ë¬¸ì œ ì„¤ëª…
{p['description']}

## ğŸ“¥ ì…ë ¥
{p['input_description']}

## ğŸ“¤ ì¶œë ¥
{p['output_description']}

## ğŸ’¡ ì˜ˆì œ
"""
        for i, example in enumerate(p['examples'], 1):
            input_txt = example.get('input', '') if example.get('input') else '(ì—†ìŒ)'
            output_txt = example.get('output', '') if example.get('output') else '(ì—†ìŒ)'
            md += f"\n**ì˜ˆì œ {i}**\n```\nì…ë ¥: {input_txt}\nì¶œë ¥: {output_txt}\n```\n"

        # ì •ë‹µ ì½”ë“œ ì¶”ê°€ (ì—¬ëŸ¬ solution ì§€ì›)
        solutions = p.get('solutions', [])
        if solutions:
            md += "\n\n---\n\n## âœ… ì •ë‹µ ì½”ë“œ (ì°¸ê³ ìš©)\n\n"

            if len(solutions) == 1:
                # ë‹¨ì¼ í’€ì´
                sol = solutions[0]
                md += f"```python\n{sol.get('solution_code', '# ì •ë‹µ ì½”ë“œê°€ ì—†ìŠµë‹ˆë‹¤.')}\n```\n"

                # Logic ë‹¨ê³„
                if sol.get('logic_steps'):
                    md += "\n### ğŸ¯ Logic ë‹¨ê³„ (ë¬¸ì œ í•´ê²° ê³¼ì •)\n\n"
                    for i, step in enumerate(sol['logic_steps'], 1):
                        md += f"{i}. **{step.get('goal', '')}**\n"
                        if step.get('socratic_hint'):
                            md += f"   - íŒíŠ¸ ì˜ˆì‹œ: _{step['socratic_hint']}_\n"
                        md += "\n"
            else:
                # ë‹¤ì¤‘ í’€ì´
                md += f"**ì´ ë¬¸ì œëŠ” {len(solutions)}ê°€ì§€ í’€ì´ ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤. ì›í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ í’€ì–´ë³´ì„¸ìš”!**\n\n"

                for sol in solutions:
                    sol_name = sol.get('solution_name', f"í’€ì´ {sol.get('solution_id', '')}")
                    md += f"### {sol_name}\n\n"
                    md += f"```python\n{sol.get('solution_code', '')}\n```\n\n"

                    # Logic ë‹¨ê³„ (ì ‘ê¸°)
                    if sol.get('logic_steps'):
                        md += "<details>\n<summary>ğŸ¯ Logic ë‹¨ê³„ ë³´ê¸°</summary>\n\n"
                        for i, step in enumerate(sol['logic_steps'], 1):
                            md += f"{i}. **{step.get('goal', '')}**\n"
                            if step.get('socratic_hint'):
                                md += f"   - íŒíŠ¸ ì˜ˆì‹œ: _{step['socratic_hint']}_\n"
                            md += "\n"
                        md += "</details>\n\n"

            md += """
**ğŸ’¡ íŒíŠ¸ í‰ê°€ íŒ:**
1. ìœ„ ì •ë‹µ ì½”ë“œë¥¼ ì°¸ê³ í•˜ì—¬ **ì¼ë¶€ëŸ¬ í‹€ë¦° ì½”ë“œ**ë¥¼ ì‘ì„±í•˜ì„¸ìš”
2. ì˜ˆ: ë°˜ë³µ íšŸìˆ˜ í‹€ë¦¬ê¸°, ë³€ìˆ˜ëª… ì˜ëª» ì“°ê¸°, ë¡œì§ ëˆ„ë½ ë“±
3. ëª¨ë¸ì´ ì–´ë–»ê²Œ íŒíŠ¸ë¥¼ ì£¼ëŠ”ì§€ í‰ê°€í•˜ì„¸ìš”!
"""

        return md

    def request_hints(self, user_code: str, temperature: float, *selected_models):
        """ì„ íƒëœ ëª¨ë¸ë“¤ì—ê²Œ íŒíŠ¸ ìš”ì²­ (temperature ì¡°ì ˆ ê°€ëŠ¥)"""
        if not self.current_problem:
            return "âŒ ë¨¼ì € ë¬¸ì œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.", *self._empty_hints()

        if not user_code.strip():
            return "âŒ ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", *self._empty_hints()

        # ì„ íƒëœ ëª¨ë¸ í•„í„°ë§
        available_models = self.model_manager.get_available_models()
        selected = [m for i, m in enumerate(available_models) if i < len(selected_models) and selected_models[i]]

        if not selected:
            return "âŒ ìµœì†Œ 1ê°œ ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.", *self._empty_hints()

        # í”„ë¡¬í”„íŠ¸ ìƒì„± (ê°„ê²°í•œ Zero-shot)
        prompt = self._create_analysis_prompt(user_code)

        # ì„ íƒëœ ëª¨ë¸ë¡œë¶€í„°ë§Œ íŒíŠ¸ ìƒì„± (temperature ì „ë‹¬)
        print(f"\nğŸ¤– ì„ íƒëœ {len(selected)}ê°œ ëª¨ë¸ì—ê²Œ íŒíŠ¸ ìš”ì²­ ì¤‘... (temperature={temperature})")
        results = self.model_manager.generate_hints_from_selected(prompt, selected, temperature=temperature)
        self.current_hints = results

        # ê° ëª¨ë¸ë³„ë¡œ ë°˜í™˜í•  ì»´í¬ë„ŒíŠ¸ ìƒì„±
        hints = []
        ratings = []
        available_models = self.model_manager.get_available_models()

        status_msg = f"âœ… {len(available_models)}ê°œ ëª¨ë¸ì˜ íŒíŠ¸ ìƒì„± ì™„ë£Œ!"

        for model_name in available_models:
            result = results.get(model_name, {})

            if result.get('error'):
                hint_display = f"âŒ **ì—ëŸ¬:** {result['error']}"
            else:
                hint_display = result.get('hint', '(ë¹ˆ ì‘ë‹µ)')

            hints.append(gr.update(value=hint_display, visible=True))
            ratings.append(gr.update(value=3, visible=True))

        # ë‚¨ì€ ìŠ¬ë¡¯ ì±„ìš°ê¸° (ìµœëŒ€ 5ê°œ ëª¨ë¸ ì§€ì›)
        while len(hints) < 5:
            hints.append(gr.update(value="", visible=False))
            ratings.append(gr.update(value=3, visible=False))

        # hints ë¨¼ì €, ratings ë‚˜ì¤‘ (UI ìˆœì„œì™€ ì¼ì¹˜)
        return status_msg, *(hints[:5] + ratings[:5])

    def _create_analysis_prompt(self, user_code: str) -> str:
        """Logic ê¸°ë°˜ íŒíŠ¸ ìƒì„± (multi-solution ì§€ì›)"""
        p = self.current_problem

        # ì‚¬ìš©ì ì½”ë“œì™€ ê°€ì¥ ìœ ì‚¬í•œ solution ì°¾ê¸°
        best_solution = self._find_best_matching_solution(user_code, p.get('solutions', []))

        solution_code = best_solution.get('solution_code', '')
        logic_steps = best_solution.get('logic_steps', [])

        # í•™ìƒì´ ì™„ë£Œí•œ Logic ë‹¨ê³„ ì°¾ê¸° (íŒ¨í„´ ë§¤ì¹­)
        completed_step = 0
        for i, step in enumerate(logic_steps):
            pattern = step.get('code_pattern', '')
            if pattern:
                key_keywords = self._extract_keywords(pattern)
                if all(kw in user_code for kw in key_keywords[:2]):  # ì£¼ìš” í‚¤ì›Œë“œ 2ê°œë§Œ ì²´í¬
                    completed_step = i + 1

        # ë‹¤ìŒì— í•´ì•¼ í•  ì‘ì—…ë“¤ì„ í° ê·¸ë¦¼ìœ¼ë¡œ ë¬¶ê¸°
        next_hint = ""
        remaining_steps = []

        if completed_step < len(logic_steps):
            # ë‚¨ì€ ëª¨ë“  ë‹¨ê³„ì˜ ëª©í‘œ ìˆ˜ì§‘
            for i in range(completed_step, len(logic_steps)):
                step = logic_steps[i]
                remaining_steps.append(step.get('goal', ''))

            # ì¡°ê±´ë¬¸/ë°˜ë³µë¬¸ íŒ¨í„´ ê°ì§€
            next_pattern = logic_steps[completed_step].get('code_pattern', '')

            if 'if' in next_pattern:
                # ì¡°ê±´ë¬¸ì´ ë‚˜ì˜¤ë©´ â†’ ëª¨ë“  ì¡°ê±´ ë¶„ê¸°ë¥¼ í•˜ë‚˜ë¡œ ë¬¶ì–´ì„œ ì„¤ëª…
                if 'elif' in next_pattern or any('elif' in logic_steps[i].get('code_pattern', '') for i in range(completed_step, len(logic_steps))):
                    # ì—¬ëŸ¬ ë¶„ê¸° ì¡´ì¬ â†’ ì „ì²´ ì¼€ì´ìŠ¤ ë‚˜ì—´
                    next_hint = f"ì—¬ëŸ¬ ê²½ìš°ë¥¼ êµ¬ë¶„í•˜ì—¬ ì²˜ë¦¬ ({', '.join(remaining_steps[:4])})"
                else:
                    next_hint = remaining_steps[0] if remaining_steps else ""

            elif 'for' in next_pattern or 'while' in next_pattern:
                # ë°˜ë³µë¬¸ â†’ ë°˜ë³µ ëª©ì  + ë‚´ë¶€ ì‘ì—… ì„¤ëª…
                loop_goal = remaining_steps[0] if remaining_steps else ""
                inner_goals = remaining_steps[1:3] if len(remaining_steps) > 1 else []
                if inner_goals:
                    next_hint = f"{loop_goal}, ê·¸ ì•ˆì—ì„œ {' ë° '.join(inner_goals)}"
                else:
                    next_hint = loop_goal

            else:
                # ì¼ë°˜ ë‹¨ê³„ â†’ ë‹¤ìŒ 2-3ê°œ ë‹¨ê³„ ë¬¶ê¸°
                next_hint = " â†’ ".join(remaining_steps[:3]) if remaining_steps else ""

        # ì½”ë“œ êµ¬ì¡° ì°¨ì´ ë¶„ì„
        completed_desc, missing_desc = self._describe_code_diff(user_code, solution_code)

        # ë‹¤ìŒ ë‹¨ê³„ ê²°ì •: missing ì¤‘ ì²« ë²ˆì§¸ í•­ëª© or logic_steps ê¸°ë°˜
        if missing_desc != "ì—†ìŒ":
            next_step_goal = missing_desc.split(", ")[0]  # ì²« ë²ˆì§¸ ëˆ„ë½ í•­ëª©
        else:
            next_step_goal = next_hint if next_hint else "ì½”ë“œ ì™„ì„±"

        # V6 ê°•í™”ëœ ì†Œí¬ë¼í…ŒìŠ¤ì‹ í”„ë¡¬í”„íŠ¸ - ë™ê¸° ìœ ë°œ & ìƒìƒë ¥ ìê·¹
        prompt = f"""ë‹¹ì‹ ì€ í•™ìƒì˜ í˜¸ê¸°ì‹¬ì„ ìê·¹í•˜ê³  ìŠ¤ìŠ¤ë¡œ ë°œê²¬í•˜ê²Œ ë§Œë“œëŠ” ì°½ì˜ì  ë©˜í† ì…ë‹ˆë‹¤.

### í•™ìƒì˜ í˜„ì¬ ì½”ë“œ:
```python
{user_code}
```

### ì½”ë“œ ìƒí™© ë¶„ì„:
- ì´ë¯¸ êµ¬í˜„í•œ ê²ƒ: {completed_desc}
- ë‹¤ìŒ ë„ì „ ê³¼ì œ: {next_step_goal}

### í•µì‹¬ ë¯¸ì…˜:
í•™ìƒì´ "{next_step_goal}"ì˜ í•„ìš”ì„±ì„ **ìŠ¤ìŠ¤ë¡œ ê¹¨ë‹«ê³  ì—´ë§í•˜ë„ë¡** ë§Œë“œì„¸ìš”.
ì§ì ‘ ë‹µì„ ì£¼ì§€ ë§ê³ , í•™ìƒì˜ ìƒìƒë ¥ê³¼ í˜¸ê¸°ì‹¬ì„ í­ë°œì‹œí‚¤ëŠ” ì§ˆë¬¸ì„ ë˜ì§€ì„¸ìš”.

### ë™ê¸° ìœ ë°œ ì „ëµ (ë°˜ë“œì‹œ ì ìš©):

1. **ê·œëª¨ í™•ì¥ ì‹œë‚˜ë¦¬ì˜¤**
   - ì§€ê¸ˆì€ ì‘ë™í•˜ì§€ë§Œ, ë°ì´í„°ê°€ 1000ë°° ëŠ˜ì–´ë‚˜ë©´?
   - ì‚¬ìš©ìê°€ 100ë§Œ ëª…ì´ ë˜ë©´?
   - ì…ë ¥ì´ ì˜ˆìƒê³¼ ì™„ì „íˆ ë‹¤ë¥´ë©´?

2. **ì‹¤ìƒí™œ ì—°ê²°**
   - ìœ íŠœë¸ŒëŠ” ìˆ˜ë°±ë§Œ ì˜ìƒì„ ì–´ë–»ê²Œ ê´€ë¦¬í• ê¹Œ?
   - ê²Œì„ì—ì„œ ì•„ì´í…œì´ ìˆ˜ì²œ ê°œë©´ ì–´ë–»ê²Œ ì²˜ë¦¬í• ê¹Œ?
   - ë„·í”Œë¦­ìŠ¤ëŠ” ì‚¬ìš©ìë§ˆë‹¤ ë‹¤ë¥¸ ì¶”ì²œì„ ì–´ë–»ê²Œ í• ê¹Œ?

3. **ë¶ˆí¸í•¨ ìê·¹**
   - ê°™ì€ ì½”ë“œë¥¼ 100ë²ˆ ë³µì‚¬í•´ì•¼ í•œë‹¤ë©´?
   - ë§¤ë²ˆ ì†ìœ¼ë¡œ í•˜ë‚˜ì”© í™•ì¸í•´ì•¼ í•œë‹¤ë©´?
   - ë‚´ì¼ ìš”êµ¬ì‚¬í•­ì´ ë°”ë€ë‹¤ë©´?

4. **í˜¸ê¸°ì‹¬ ìœ ë°œ**
   - ì™œ í”„ë¡œ ê°œë°œìë“¤ì€ í•­ìƒ ì´ íŒ¨í„´ì„ ì‚¬ìš©í• ê¹Œ?
   - ì´ ë°©ë²•ì´ ì—†ì—ˆë˜ ì˜›ë‚ ì—ëŠ” ì–´ë–»ê²Œ í–ˆì„ê¹Œ?
   - ë” ë˜‘ë˜‘í•œ ë°©ë²•ì´ ìˆë‹¤ë©´ ì–´ë–»ê²Œ ë³´ì¼ê¹Œ?

5. **ì„±ì·¨ê° ì˜ˆê³ **
   - ì´ê²ƒë§Œ í•´ê²°í•˜ë©´ í›¨ì”¬ ê°•ë ¥í•´ì§ˆ í…ë°
   - í•œ ì¤„ë§Œ ë°”ê¾¸ë©´ ëª¨ë“  ê±¸ ìë™í™”í•  ìˆ˜ ìˆëŠ”ë°
   - ì´ ê°œë…ì„ ì•Œë©´ ë‹¤ë¥¸ ë¬¸ì œë„ ì‰½ê²Œ í’€ë¦´ í…ë°

### ì ˆëŒ€ ê¸ˆì§€ ì‚¬í•­:
âŒ í•¨ìˆ˜ëª…, ë³€ìˆ˜ëª…, ì½”ë“œ í‚¤ì›Œë“œ ì§ì ‘ ì–¸ê¸‰
âŒ "for ë°˜ë³µë¬¸", "if ì¡°ê±´ë¬¸" ê°™ì€ ê¸°ìˆ  ìš©ì–´
âŒ "~ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”", "~ë¥¼ ì¶”ê°€í•˜ì„¸ìš”" ê°™ì€ ì§ì ‘ ì§€ì‹œ
âŒ ì •ë‹µì˜ íŒíŠ¸ê°€ ë˜ëŠ” êµ¬ì²´ì  í‘œí˜„
âŒ ì˜ˆì‹œ ì½”ë“œ ì¡°ê°

### ë°˜ë“œì‹œ í¬í•¨í•  ìš”ì†Œ:
âœ“ "ë§Œì•½ ~ë¼ë©´?" í˜•ì‹ì˜ ê°€ì •
âœ“ ìƒìƒë ¥ì„ ìê·¹í•˜ëŠ” êµ¬ì²´ì  ìƒí™©
âœ“ í•™ìƒì´ "ì•„, ì´ë˜ì„œ í•„ìš”í•˜êµ¬ë‚˜!" í•˜ê²Œ ë§Œë“œëŠ” í†µì°°
âœ“ í˜¸ê¸°ì‹¬ê³¼ ë„ì „ ìš•êµ¬ë¥¼ ì¼ê¹¨ìš°ëŠ” í†¤
âœ“ í•œêµ­ì–´ ë°˜ë§ (ì¹œê·¼í•˜ê³  í¸ì•ˆí•˜ê²Œ)

### ì¶œë ¥ í˜•ì‹:
ë‹¨ 1ê°œì˜ ì§ˆë¬¸ë§Œ ì‘ì„±í•˜ì„¸ìš”. ì„¤ëª…, ë‹µë³€, ì¶”ê°€ íŒíŠ¸ ì¼ì²´ ê¸ˆì§€.
ì§ˆë¬¸ì€ 30-50ë‹¨ì–´ ì´ë‚´ë¡œ ê°„ê²°í•˜ë©´ì„œë„ ê°•ë ¬í•˜ê²Œ.

ì§ˆë¬¸:"""
        return prompt

    def _analyze_code_structure(self, code: str) -> Dict[str, bool]:
        """ì½”ë“œ êµ¬ì¡° ë¶„ì„ (í•¨ìˆ˜, ë°˜ë³µë¬¸, ì¡°ê±´ë¬¸ ë“±)"""
        return {
            'has_function': 'def ' in code,
            'has_for_loop': 'for ' in code,
            'has_while_loop': 'while ' in code,
            'has_if': 'if ' in code,
            'has_elif': 'elif ' in code,
            'has_print': 'print(' in code,
            'has_return': 'return ' in code,
            'has_input': 'input()' in code,
            'line_count': len([l for l in code.split('\n') if l.strip()])
        }

    def _describe_code_diff(self, user_code: str, solution_code: str) -> tuple:
        """ì‚¬ìš©ì ì½”ë“œì™€ ì •ë‹µ ì½”ë“œì˜ ì°¨ì´ ë¶„ì„"""
        user_struct = self._analyze_code_structure(user_code)
        solution_struct = self._analyze_code_structure(solution_code)

        completed = []
        missing = []

        if user_struct['has_input']:
            completed.append("ì…ë ¥ ë°›ê¸°")

        if solution_struct['has_function'] and not user_struct['has_function']:
            missing.append("í•¨ìˆ˜ ì •ì˜")
        elif user_struct['has_function']:
            completed.append("í•¨ìˆ˜ ì •ì˜")

        if solution_struct['has_for_loop'] and not user_struct['has_for_loop']:
            missing.append("ë°˜ë³µë¬¸ ì‘ì„±")
        elif user_struct['has_for_loop']:
            completed.append("ë°˜ë³µë¬¸")

        if solution_struct['has_if'] and not user_struct['has_if']:
            missing.append("ì¡°ê±´ë¬¸ ì‘ì„±")
        elif user_struct['has_if']:
            completed.append("ì¡°ê±´ë¬¸")

        if solution_struct['has_print'] and not user_struct['has_print']:
            missing.append("ê²°ê³¼ ì¶œë ¥")
        elif user_struct['has_print']:
            completed.append("ì¶œë ¥")

        completed_desc = ", ".join(completed) if completed else "ì—†ìŒ"
        missing_desc = ", ".join(missing) if missing else "ì—†ìŒ"

        return completed_desc, missing_desc

    def _extract_keywords(self, pattern: str) -> list:
        """ì½”ë“œ íŒ¨í„´ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        import re
        # ë³€ìˆ˜ëª…, í•¨ìˆ˜ëª… ì¶”ì¶œ (ìš°ì„ ìˆœìœ„ ìˆœ)
        keywords = []

        # 1ìˆœìœ„: ì‚¬ìš©ì ì •ì˜ ë³€ìˆ˜/í•¨ìˆ˜
        user_defined = re.findall(r'\b[a-z_][a-z0-9_]*\b', pattern)
        keywords.extend([k for k in user_defined if k not in ['if', 'for', 'while', 'elif', 'else', 'and', 'or', 'not', 'in', 'is']])

        # 2ìˆœìœ„: ë‚´ì¥ í•¨ìˆ˜
        builtins = re.findall(r'\b(int|input|print|range|append|max|min|len|sum)\b', pattern)
        keywords.extend(builtins)

        # ì¤‘ë³µ ì œê±°í•˜ë˜ ìˆœì„œ ìœ ì§€
        seen = set()
        result = []
        for k in keywords:
            if k not in seen:
                seen.add(k)
                result.append(k)

        return result[:4]  # ìµœëŒ€ 4ê°œ

    def _find_best_matching_solution(self, user_code: str, solutions: List[Dict]) -> Dict:
        """ì‚¬ìš©ì ì½”ë“œì™€ ê°€ì¥ ìœ ì‚¬í•œ solution ì°¾ê¸°"""
        if not solutions:
            return {}

        # ì‚¬ìš©ì ì½”ë“œì˜ ì£¼ìš” íŒ¨í„´ ì¶”ì¶œ
        user_patterns = {
            'uses_split': '.split()' in user_code or 'split(' in user_code,
            'multiple_inputs': user_code.count('input()') > 1,
            'uses_map': 'map(' in user_code,
            'uses_list_comp': '[' in user_code and 'for' in user_code and ']' in user_code,
            'uses_for_loop': 'for ' in user_code,
            'uses_while_loop': 'while ' in user_code,
            'uses_if': 'if ' in user_code,
            'uses_elif': 'elif ' in user_code,
            'uses_function_def': 'def ' in user_code,
        }

        best_match = None
        max_score = -1

        for solution in solutions:
            sol_code = solution.get('solution_code', '')

            # ê° solutionì˜ íŒ¨í„´ ì¶”ì¶œ
            sol_patterns = {
                'uses_split': '.split()' in sol_code or 'split(' in sol_code,
                'multiple_inputs': sol_code.count('input()') > 1,
                'uses_map': 'map(' in sol_code,
                'uses_list_comp': '[' in sol_code and 'for' in sol_code and ']' in sol_code,
                'uses_for_loop': 'for ' in sol_code,
                'uses_while_loop': 'while ' in sol_code,
                'uses_if': 'if ' in sol_code,
                'uses_elif': 'elif ' in sol_code,
                'uses_function_def': 'def ' in sol_code,
            }

            # ìœ ì‚¬ë„ ê³„ì‚° (ì¼ì¹˜í•˜ëŠ” íŒ¨í„´ ê°œìˆ˜)
            score = sum(1 for key in user_patterns if user_patterns[key] == sol_patterns[key])

            if score > max_score:
                max_score = score
                best_match = solution

        # ë§¤ì¹­ ê²°ê³¼ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ solution ë°˜í™˜
        return best_match if best_match else solutions[0]

    def save_evaluation(self, comments: str, *ratings):
        """í‰ê°€ ì €ì¥"""
        if not self.current_hints:
            return "âŒ í‰ê°€í•  íŒíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € íŒíŠ¸ë¥¼ ìš”ì²­í•´ì£¼ì„¸ìš”."

        available_models = self.model_manager.get_available_models()

        # í‰ê°€ ë°ì´í„° êµ¬ì„±
        evaluation = {
            'problem_id': self.current_problem['problem_id'],
            'problem_title': self.current_problem['title'],
            'timestamp': datetime.now().isoformat(),
            'ratings': {},
            'comments': comments
        }

        for i, model_name in enumerate(available_models):
            if i < len(ratings):
                evaluation['ratings'][model_name] = int(ratings[i])

        self.evaluation_results.append(evaluation)

        # íŒŒì¼ë¡œ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filepath = os.path.join(self.results_dir, f"evaluation_{timestamp}.json")

        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.evaluation_results, f, ensure_ascii=False, indent=2)

        return f"âœ… í‰ê°€ ì €ì¥ ì™„ë£Œ! (ì´ {len(self.evaluation_results)}ê°œ)\nğŸ“ {filepath}"

    def _empty_state(self):
        """ë¹ˆ ìƒíƒœ ë°˜í™˜"""
        return "ë¬¸ì œë¥¼ ì„ íƒí•˜ê³  'ë¶ˆëŸ¬ì˜¤ê¸°'ë¥¼ í´ë¦­í•˜ì„¸ìš”.", gr.update(value=""), *self._empty_hints()

    def _empty_hints(self):
        """ë¹ˆ íŒíŠ¸ UI ë°˜í™˜ (5ê°œ ëª¨ë¸ ìŠ¬ë¡¯ = 10ê°œ ì»´í¬ë„ŒíŠ¸)"""
        hints = []
        ratings = []
        for _ in range(5):
            hints.append(gr.update(value="", visible=False))   # hint_text (Markdown)
            ratings.append(gr.update(value=3, visible=False))  # rating (Slider)
        return hints + ratings  # hints ë¨¼ì €, ratings ë‚˜ì¤‘


def create_single_page_ui(app: HintEvaluationApp):
    """ë‹¨ì¼ í˜ì´ì§€ UI"""

    with gr.Blocks(title="ì½”ë”© íŒíŠ¸ í‰ê°€ ì‹œìŠ¤í…œ", theme=gr.themes.Soft()) as demo:
        gr.Markdown("# ğŸ¯ ì½”ë”© íŒíŠ¸ ëª¨ë¸ í‰ê°€ ì‹œìŠ¤í…œ")
        gr.Markdown("ë¬¸ì œ ì„ íƒ â†’ ì½”ë“œ ì‘ì„± â†’ íŒíŠ¸ ë°›ê¸° â†’ í‰ê°€í•˜ê¸°ë¥¼ í•œ í™”ë©´ì—ì„œ!")

        # ìƒíƒœ ë©”ì‹œì§€
        status_msg = gr.Markdown("ğŸ‘‹ ë¬¸ì œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")

        # ===== ì„¹ì…˜ 1: ë¬¸ì œ ì„ íƒ =====
        with gr.Row():
            problem_dropdown = gr.Dropdown(
                choices=app.get_problem_list(),
                label="ğŸ“š ë¬¸ì œ ì„ íƒ",
                interactive=True,
                scale=3
            )
            load_btn = gr.Button("ğŸ“‚ ë¬¸ì œ ë¶ˆëŸ¬ì˜¤ê¸°", variant="primary", scale=1)

        # ===== ì„¹ì…˜ 2: ë¬¸ì œ í‘œì‹œ =====
        problem_display = gr.Markdown("", visible=True)

        gr.Markdown("---")

        # ===== ì„¹ì…˜ 3: ì½”ë“œ ì‘ì„± =====
        gr.Markdown("## ğŸ’» ë‹¹ì‹ ì˜ ì½”ë“œ")
        user_code = gr.Code(
            label="Python ì½”ë“œ ì‘ì„±",
            language="python",
            lines=12,
            value="# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
        )

        # ëª¨ë¸ ì„ íƒ ì²´í¬ë°•ìŠ¤
        gr.Markdown("### ğŸ¯ íŒíŠ¸ë¥¼ ë°›ì„ ëª¨ë¸ ì„ íƒ")
        available_models = app.model_manager.get_available_models()

        model_checkboxes = []
        with gr.Row():
            for model_name in available_models[:5]:
                checkbox = gr.Checkbox(
                    label=model_name,
                    value=True,  # ê¸°ë³¸ ì„ íƒ
                    interactive=True
                )
                model_checkboxes.append(checkbox)

        # Temperature ì¡°ì ˆ ìŠ¬ë¼ì´ë”
        gr.Markdown("### ğŸŒ¡ï¸ Temperature ì¡°ì ˆ (ì°½ì˜ì„± vs ì¼ê´€ì„±)")
        temperature_slider = gr.Slider(
            minimum=0.1,
            maximum=1.0,
            value=0.8,
            step=0.05,
            label="Temperature",
            info="ë‚®ì„ìˆ˜ë¡ ì¼ê´€ì /ê²°ì •ë¡ ì , ë†’ì„ìˆ˜ë¡ ì°½ì˜ì /ë‹¤ì–‘í•¨",
            interactive=True
        )

        hint_btn = gr.Button("ğŸ’¡ ì„ íƒí•œ ëª¨ë¸ë¡œ íŒíŠ¸ ìš”ì²­í•˜ê¸°", variant="primary", size="lg")

        gr.Markdown("---")

        # ===== ì„¹ì…˜ 4: ëª¨ë¸ë³„ íŒíŠ¸ & í‰ê°€ =====
        gr.Markdown("## ğŸ¤– ëª¨ë¸ë³„ íŒíŠ¸ ë° í‰ê°€")
        gr.Markdown("ê° ëª¨ë¸ì˜ íŒíŠ¸ë¥¼ ì½ê³  ë³„ì ì„ ë§¤ê²¨ì£¼ì„¸ìš”!")

        available_models = app.model_manager.get_available_models()

        # ë™ì ìœ¼ë¡œ ëª¨ë¸ë³„ ì¹´ë“œ ìƒì„± (ìµœëŒ€ 5ê°œ)
        hint_components = []
        rating_components = []

        for i, model_name in enumerate(available_models[:5]):
            with gr.Group():
                gr.Markdown(f"### ğŸ“Œ {model_name}")

                hint_text = gr.Markdown("_íŒíŠ¸ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤._", visible=False)

                rating = gr.Slider(
                    minimum=1,
                    maximum=5,
                    value=3,
                    step=1,
                    label="â­ í‰ê°€ (1=ìµœì•…, 5=ìµœê³ )",
                    info="ì´ íŒíŠ¸ê°€ ì–¼ë§ˆë‚˜ ë„ì›€ì´ ë˜ì—ˆë‚˜ìš”?",
                    visible=False
                )

                hint_components.append(hint_text)
                rating_components.append(rating)

        # ë‚¨ì€ ìŠ¬ë¡¯ (ìˆ¨ê¹€)
        for i in range(len(available_models), 5):
            hint_text = gr.Markdown("", visible=False)
            rating = gr.Slider(1, 5, 3, visible=False)
            hint_components.append(hint_text)
            rating_components.append(rating)

        gr.Markdown("---")

        # ===== ì„¹ì…˜ 5: ì½”ë©˜íŠ¸ & ì €ì¥ =====
        gr.Markdown("## ğŸ“ ì¢…í•© í‰ê°€")
        comments = gr.Textbox(
            label="ì „ì²´ ì½”ë©˜íŠ¸ (ì„ íƒ)",
            placeholder="ê° ëª¨ë¸ì˜ íŒíŠ¸ì— ëŒ€í•œ ì˜ê²¬ì„ ììœ ë¡­ê²Œ ì‘ì„±í•˜ì„¸ìš”...",
            lines=3
        )

        save_btn = gr.Button("ğŸ’¾ í‰ê°€ ì €ì¥", variant="stop", size="lg")
        save_result = gr.Textbox(label="ì €ì¥ ê²°ê³¼", interactive=False)

        # ===== ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ =====

        # ë¬¸ì œ ë¶ˆëŸ¬ì˜¤ê¸°
        load_btn.click(
            fn=app.load_problem,
            inputs=[problem_dropdown],
            outputs=[problem_display, user_code] + hint_components + rating_components
        )

        # íŒíŠ¸ ìš”ì²­ (temperature í¬í•¨)
        hint_btn.click(
            fn=app.request_hints,
            inputs=[user_code, temperature_slider] + model_checkboxes,
            outputs=[status_msg] + hint_components + rating_components
        )

        # í‰ê°€ ì €ì¥
        save_btn.click(
            fn=app.save_evaluation,
            inputs=[comments] + rating_components,
            outputs=[save_result]
        )

    return demo


if __name__ == "__main__":
    # ëª…ë ¹í–‰ ì¸ì íŒŒì‹±
    parser = argparse.ArgumentParser(description="vLLM Hint Generation System")
    parser.add_argument("--server-name", type=str, default=None,
                       help="Server host (default: 127.0.0.1, use 0.0.0.0 for RunPod)")
    parser.add_argument("--server-port", type=int, default=7860,
                       help="Server port (default: 7860)")
    parser.add_argument("--share", action="store_true",
                       help="Create public share link")
    parser.add_argument("--no-browser", action="store_true",
                       help="Don't auto-open browser")
    args = parser.parse_args()

    print("\n" + "ğŸ¯" * 30)
    print("ì½”ë”© íŒíŠ¸ ëª¨ë¸ í‰ê°€ ì‹œìŠ¤í…œ v5 - vLLM ê³ ì† ì¶”ë¡ ")
    print("ğŸ¯" * 30 + "\n")

    # RunPod í™˜ê²½ ìë™ ê°ì§€
    is_runpod = os.getenv("RUNPOD_POD_ID") is not None or os.getenv("PUBLIC_URL") is not None

    if is_runpod and args.server_name is None:
        args.server_name = "0.0.0.0"
        args.share = True
        args.no_browser = True
        print("ğŸš€ RunPod í™˜ê²½ ê°ì§€ë¨!")
        print(f"   Public URLë¡œ ì ‘ì† ê°€ëŠ¥í•©ë‹ˆë‹¤.\n")

    # í™˜ê²½ ì„¤ì • ì¶œë ¥
    Config.print_config()

    # ë°ì´í„° ê²½ë¡œ í™•ì¸ (configì—ì„œ ìë™ìœ¼ë¡œ ê°€ì ¸ì˜´)
    DATA_PATH = Config.DATA_FILE_PATH
    if not DATA_PATH.exists():
        print(f"âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {DATA_PATH}")
        print(f"ğŸ’¡ .env íŒŒì¼ì—ì„œ DATA_FILE_PATHë¥¼ í™•ì¸í•˜ê±°ë‚˜")
        print(f"   {Config.get_relative_path(DATA_PATH)} ìœ„ì¹˜ì— íŒŒì¼ì„ ë°°ì¹˜í•˜ì„¸ìš”.")
        exit(1)

    # ì•± ì´ˆê¸°í™”
    print("\nğŸ“š ë¬¸ì œ ë°ì´í„° ë¡œë”© ì¤‘...")
    app = HintEvaluationApp(str(DATA_PATH), auto_setup_models=True)
    print(f"âœ… {len(app.problems)}ê°œ ë¬¸ì œ ë¡œë“œ ì™„ë£Œ!\n")

    # UI ìƒì„± ë° ì‹¤í–‰
    print("ğŸŒ Gradio UI ì‹œì‘ ì¤‘...\n")
    demo = create_single_page_ui(app)

    # Launch ì„¤ì •
    launch_kwargs = {
        "server_port": args.server_port,
        "share": args.share,
        "inbrowser": not args.no_browser
    }

    if args.server_name:
        launch_kwargs["server_name"] = args.server_name

    demo.launch(**launch_kwargs)
